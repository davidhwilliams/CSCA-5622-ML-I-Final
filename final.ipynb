{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCA 5622 Machine Learning I Final Project\n",
    "\n",
    "**Goal**: Identify a Supervised Learning problem to perform EDA and model analysis.\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "1. Jupyter notebook showing a supervised learning problem description, EDA procedure, analysis (model building and training), result, and discussion/conclusion\n",
    "2. Video presentation or demo (5-15min) in `.mp4` format.\n",
    "\n",
    "   - What problem do you solve?\n",
    "   - What ML approach do you use, or what methods does your app use?\n",
    "   - Show the result or run an app demo.\n",
    "\n",
    "3. [Public GitHub Repo](https://github.com/davidhwilliams/CSCA-5622-ML-I-Final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Focus\n",
    "\n",
    "Predicting CVSS Score Severity based on `description`, `CPEs`, `keywords`.\n",
    "\n",
    "## Links and Data Feeds\n",
    "\n",
    "- https://nvd.nist.gov/vuln\n",
    "- [NVD CVE API Guide](https://nvd.nist.gov/developers/vulnerabilities)\n",
    "\n",
    "## Steps\n",
    "\n",
    "### 1. Data Collection\n",
    "\n",
    "- **Download CVE Dataset** from the NVD (includes CVSS scores, descriptions, affected software/hardware, date of discovery).\n",
    "\n",
    "### 2. Data Preprocessing\n",
    "\n",
    "- **Handle missing data**: Remove or impute missing values in descriptions, affected software, and CVSS scores.\n",
    "- **Text preprocessing**: For vulnerability descriptions:Remove special characters, stop words, and tokenize. Apply lemmatization or stemming.\n",
    "- **Keyword extraction**: Use TF-IDF or CountVectorizer (bag-of-words).\n",
    "- **Categorical encoding** for affected software/hardware: One-hot encoding or label encoding. Use dimensionality reduction techniques like PCA.\n",
    "\n",
    "### 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "- **Understand the target variable**: Plot the distribution of CVSS severity (Low, Medium, High, Critical). Check for class imbalance.\n",
    "- **Analyze text data**:\n",
    "  - Word cloud visualizations for different severity levels.\n",
    "  - Bar plots for keyword frequency by severity category.\n",
    "- **Analyze affected software/hardware**:\n",
    "  - Histograms or bar charts for common affected software/hardware in each severity.\n",
    "- **Correlation analysis**:\n",
    "  - Correlation matrix to identify strong relationships between features and CVSS severity.\n",
    "\n",
    "### 4. Feature Engineering\n",
    "\n",
    "- **Text-based features**:\n",
    "  - Use TF-IDF or Word2Vec for numerical representations.\n",
    "  - Create features based on keyword counts, description length, etc.\n",
    "- **Categorical features**:\n",
    "  - Count the number of affected products or types of products.\n",
    "- **Date-based features** (if applicable): Create features like vulnerability age, seasonality, etc.\n",
    "\n",
    "### 5. Splitting the Data\n",
    "\n",
    "- Split the data into **training** and **testing** sets (70/30 or 80/20 split).\n",
    "\n",
    "### 6. Model Selection and Training\n",
    "\n",
    "- Use classification models:\n",
    "  - **Logistic Regression** (baseline model).\n",
    "  - **Random Forest**.\n",
    "  - **Gradient Boosting (XGBoost/LightGBM)**.\n",
    "  - **Naive Bayes** for text-heavy models.\n",
    "  - **Support Vector Machine (SVM)** with TF-IDF.\n",
    "- Handle **class imbalance** using:\n",
    "  - **Oversampling** (SMOTE) or **undersampling**.\n",
    "  - Adjust class weights in models.\n",
    "\n",
    "### 7. Model Evaluation\n",
    "\n",
    "- Use metrics:\n",
    "  - **Accuracy** (for balanced data).\n",
    "  - **Precision, Recall, F1-score** (for imbalanced data).\n",
    "  - **Confusion Matrix** to visualize performance.\n",
    "- **Cross-validation**: Use k-fold cross-validation for generalization.\n",
    "\n",
    "### 8. Model Tuning\n",
    "\n",
    "- **Hyperparameter tuning** with:\n",
    "  - **GridSearchCV** or **RandomSearchCV**.\n",
    "  - Tune parameters like number of estimators, tree depth, learning rate.\n",
    "\n",
    "### 9. Model Interpretation\n",
    "\n",
    "- **Feature importance**: Visualize feature importance for tree-based models.\n",
    "- **SHAP values or LIME** for interpreting complex models.\n",
    "\n",
    "### 10. Model Deployment and Conclusions\n",
    "\n",
    "- Discuss which features (descriptions, keywords, software) were most predictive.\n",
    "- Identify limitations (e.g., class imbalance, noisy text data).\n",
    "- Suggest improvements with more data or refined feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib.colors import Normalize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
